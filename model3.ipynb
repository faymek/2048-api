{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = []\n",
    "with open(\"datatrain2M.csv\") as f:\n",
    "    for line in f:\n",
    "        piece = eval(line)\n",
    "        if max(piece)<7 :\n",
    "            data_raw.append(piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "data7 = []\n",
    "with open(\"train7.json\",'r') as f:\n",
    "    data7 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(data4)\n",
    "# 输入范围0-15，除以16做归一化\n",
    "images = (dataset[:,:-1]/16).astype(\"float32\")\n",
    "labels = dataset[:,-1].astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33995, 64)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.0001\n",
    "num_steps = 10000\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "num_input =  64# MNIST data input (img shape: 28*28)\n",
    "num_classes = 4 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.5 # Dropout, probability to drop a unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the neural network\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    \n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x = x_dict['images']\n",
    "\n",
    "        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x, shape=[-1, 8, 8, 1])\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 3\n",
    "        conv1 = tf.layers.conv2d(x, 32, 4, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        #conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        #conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at training and prediction time, we\n",
    "    # need to create 2 distinct computation graphs that still share the same weights.\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "        \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './mymodels/model4', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "model = tf.estimator.Estimator(model_fn=model_fn,model_dir=\"./mymodels/model4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-120000\n",
      "INFO:tensorflow:Saving checkpoints for 120001 into ./mymodels/model4/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.5528741, step = 120001\n",
      "INFO:tensorflow:global_step/sec: 26.3971\n",
      "INFO:tensorflow:loss = 0.700449, step = 120101 (3.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3393\n",
      "INFO:tensorflow:loss = 0.569626, step = 120201 (5.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5837\n",
      "INFO:tensorflow:loss = 0.61729074, step = 120301 (3.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0129\n",
      "INFO:tensorflow:loss = 0.59306914, step = 120401 (4.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9216\n",
      "INFO:tensorflow:loss = 0.62096107, step = 120501 (3.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6284\n",
      "INFO:tensorflow:loss = 0.6714061, step = 120601 (3.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6063\n",
      "INFO:tensorflow:loss = 0.60257494, step = 120701 (3.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5635\n",
      "INFO:tensorflow:loss = 0.6543088, step = 120801 (3.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7597\n",
      "INFO:tensorflow:loss = 0.63957775, step = 120901 (2.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0542\n",
      "INFO:tensorflow:loss = 0.62649864, step = 121001 (2.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.9751\n",
      "INFO:tensorflow:loss = 0.6709101, step = 121101 (3.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.3676\n",
      "INFO:tensorflow:loss = 0.6002746, step = 121201 (2.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9355\n",
      "INFO:tensorflow:loss = 0.6457207, step = 121301 (3.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1899\n",
      "INFO:tensorflow:loss = 0.5881276, step = 121401 (3.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.056\n",
      "INFO:tensorflow:loss = 0.4897513, step = 121501 (3.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7183\n",
      "INFO:tensorflow:loss = 0.7063117, step = 121601 (3.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5371\n",
      "INFO:tensorflow:loss = 0.57357514, step = 121701 (3.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.7157\n",
      "INFO:tensorflow:loss = 0.6043503, step = 121801 (2.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.18\n",
      "INFO:tensorflow:loss = 0.62439287, step = 121901 (2.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4414\n",
      "INFO:tensorflow:loss = 0.6345235, step = 122001 (2.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.1108\n",
      "INFO:tensorflow:loss = 0.58958364, step = 122101 (2.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9469\n",
      "INFO:tensorflow:loss = 0.51143336, step = 122201 (3.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3322\n",
      "INFO:tensorflow:loss = 0.6135959, step = 122301 (3.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.3366\n",
      "INFO:tensorflow:loss = 0.71782947, step = 122401 (2.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.7443\n",
      "INFO:tensorflow:loss = 0.50854367, step = 122501 (3.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.9192\n",
      "INFO:tensorflow:loss = 0.5927838, step = 122601 (2.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0049\n",
      "INFO:tensorflow:loss = 0.6234858, step = 122701 (3.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5834\n",
      "INFO:tensorflow:loss = 0.6196395, step = 122801 (3.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.8744\n",
      "INFO:tensorflow:loss = 0.5930978, step = 122901 (2.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.3834\n",
      "INFO:tensorflow:loss = 0.5499577, step = 123001 (3.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7584\n",
      "INFO:tensorflow:loss = 0.60402673, step = 123101 (2.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.819\n",
      "INFO:tensorflow:loss = 0.6229505, step = 123201 (3.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1649\n",
      "INFO:tensorflow:loss = 0.61310893, step = 123301 (3.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3738\n",
      "INFO:tensorflow:loss = 0.6400082, step = 123401 (2.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8621\n",
      "INFO:tensorflow:loss = 0.5108241, step = 123501 (2.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3319\n",
      "INFO:tensorflow:loss = 0.60017663, step = 123601 (3.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.8962\n",
      "INFO:tensorflow:loss = 0.5284058, step = 123701 (2.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.1809\n",
      "INFO:tensorflow:loss = 0.55162096, step = 123801 (2.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.2505\n",
      "INFO:tensorflow:loss = 0.5168893, step = 123901 (2.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6096\n",
      "INFO:tensorflow:loss = 0.6747235, step = 124001 (2.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3369\n",
      "INFO:tensorflow:loss = 0.64256465, step = 124101 (3.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9408\n",
      "INFO:tensorflow:loss = 0.52098525, step = 124201 (5.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.5341\n",
      "INFO:tensorflow:loss = 0.5545352, step = 124301 (2.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.119\n",
      "INFO:tensorflow:loss = 0.6829079, step = 124401 (2.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6655\n",
      "INFO:tensorflow:loss = 0.7004644, step = 124501 (3.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1605\n",
      "INFO:tensorflow:loss = 0.4963929, step = 124601 (3.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.2297\n",
      "INFO:tensorflow:loss = 0.5787033, step = 124701 (2.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7499\n",
      "INFO:tensorflow:loss = 0.6596832, step = 124801 (3.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7929\n",
      "INFO:tensorflow:loss = 0.5886003, step = 124901 (2.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.6069\n",
      "INFO:tensorflow:loss = 0.4907963, step = 125001 (2.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1099\n",
      "INFO:tensorflow:loss = 0.54214644, step = 125101 (3.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.182\n",
      "INFO:tensorflow:loss = 0.68382335, step = 125201 (3.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0856\n",
      "INFO:tensorflow:loss = 0.53435886, step = 125301 (3.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4726\n",
      "INFO:tensorflow:loss = 0.6266853, step = 125401 (4.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4007\n",
      "INFO:tensorflow:loss = 0.6447807, step = 125501 (3.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7157\n",
      "INFO:tensorflow:loss = 0.67054844, step = 125601 (2.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4632\n",
      "INFO:tensorflow:loss = 0.51403666, step = 125701 (2.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9702\n",
      "INFO:tensorflow:loss = 0.6026816, step = 125801 (3.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9325\n",
      "INFO:tensorflow:loss = 0.5050395, step = 125901 (3.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4203\n",
      "INFO:tensorflow:loss = 0.42895392, step = 126001 (3.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.2319\n",
      "INFO:tensorflow:loss = 0.5332346, step = 126101 (3.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4499\n",
      "INFO:tensorflow:loss = 0.67470694, step = 126201 (3.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8521\n",
      "INFO:tensorflow:loss = 0.5073289, step = 126301 (3.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.443\n",
      "INFO:tensorflow:loss = 0.61172235, step = 126401 (3.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.3199\n",
      "INFO:tensorflow:loss = 0.5745978, step = 126501 (2.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7159\n",
      "INFO:tensorflow:loss = 0.53701854, step = 126601 (3.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.9305\n",
      "INFO:tensorflow:loss = 0.4685048, step = 126701 (2.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.003\n",
      "INFO:tensorflow:loss = 0.51361895, step = 126801 (3.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8656\n",
      "INFO:tensorflow:loss = 0.63809067, step = 126901 (4.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8738\n",
      "INFO:tensorflow:loss = 0.56169903, step = 127001 (3.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7544\n",
      "INFO:tensorflow:loss = 0.44776714, step = 127101 (2.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.003\n",
      "INFO:tensorflow:loss = 0.6520341, step = 127201 (2.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.0547\n",
      "INFO:tensorflow:loss = 0.5619726, step = 127301 (2.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2459\n",
      "INFO:tensorflow:loss = 0.51701224, step = 127401 (3.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4397\n",
      "INFO:tensorflow:loss = 0.56122625, step = 127501 (3.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7692\n",
      "INFO:tensorflow:loss = 0.5269991, step = 127601 (2.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.7343\n",
      "INFO:tensorflow:loss = 0.63523865, step = 127701 (3.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7899\n",
      "INFO:tensorflow:loss = 0.6222322, step = 127801 (4.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.5987\n",
      "INFO:tensorflow:loss = 0.5780648, step = 127901 (2.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.9888\n",
      "INFO:tensorflow:loss = 0.5945394, step = 128001 (2.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8143\n",
      "INFO:tensorflow:loss = 0.5702603, step = 128101 (2.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.786\n",
      "INFO:tensorflow:loss = 0.5647898, step = 128201 (2.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.7295\n",
      "INFO:tensorflow:loss = 0.55686235, step = 128301 (2.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.3927\n",
      "INFO:tensorflow:loss = 0.63422513, step = 128401 (2.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.6287\n",
      "INFO:tensorflow:loss = 0.63082004, step = 128501 (2.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.7067\n",
      "INFO:tensorflow:loss = 0.5030266, step = 128601 (2.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.142\n",
      "INFO:tensorflow:loss = 0.54716444, step = 128701 (2.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.1972\n",
      "INFO:tensorflow:loss = 0.59409785, step = 128801 (2.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.9668\n",
      "INFO:tensorflow:loss = 0.46949613, step = 128901 (2.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.6057\n",
      "INFO:tensorflow:loss = 0.5130447, step = 129001 (2.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.5809\n",
      "INFO:tensorflow:loss = 0.5002147, step = 129101 (2.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.3709\n",
      "INFO:tensorflow:loss = 0.5886848, step = 129201 (2.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6782\n",
      "INFO:tensorflow:loss = 0.66106534, step = 129301 (3.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.7853\n",
      "INFO:tensorflow:loss = 0.5323819, step = 129401 (2.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.0363\n",
      "INFO:tensorflow:loss = 0.54151547, step = 129501 (2.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.821\n",
      "INFO:tensorflow:loss = 0.5682687, step = 129601 (2.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2538\n",
      "INFO:tensorflow:loss = 0.51074266, step = 129701 (3.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2267\n",
      "INFO:tensorflow:loss = 0.66344035, step = 129801 (2.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.7301\n",
      "INFO:tensorflow:loss = 0.5315763, step = 129901 (2.965 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 130000 into ./mymodels/model4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.683758.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f355f91e710>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': images}, y=labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model.train(input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-12-13-14:12:43\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-13-14:12:46\n",
      "INFO:tensorflow:Saving dict for global step 130000: accuracy = 0.76281804, global_step = 130000, loss = 0.58623785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.76281804, 'global_step': 130000, 'loss': 0.58623785}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': images}, y=labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mymodels/model3/model.ckpt-113000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKq/DoIdyGVkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f355f6e8ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHEiMwIHECBxI7L/d/7gYUvTQxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3587cfec88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f355fde6a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f355fa2d860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 2\n"
     ]
    }
   ],
   "source": [
    "# Predict single images\n",
    "n_images = 4\n",
    "# Get images from test set\n",
    "test_images = images[1000:1000+n_images]\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': images}, shuffle=False)\n",
    "# Use the model to predict the images class\n",
    "preds = list(model.predict(input_fn))\n",
    "\n",
    "# Display\n",
    "for i in range(n_images):\n",
    "    plt.imshow(np.reshape(test_images[i], [8, 8]), cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Model prediction:\", preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game2048.game import Game\n",
    "from game2048.displays import Display, IPythonDisplay\n",
    "from game2048.agents import Agent, RandomAgent, ExpectiMaxAgent\n",
    "# from game2048.displayer import Displayer\n",
    "display1 = Display()\n",
    "display2 = IPythonDisplay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class MyAgent(Agent):\n",
    "\n",
    "    def __init__(self, game, display=None):\n",
    "        super().__init__(game, display)\n",
    "        self.testgame = Game(4, random=False)\n",
    "        self.testgame.enable_rewrite_board = True\n",
    "        \n",
    "    def step(self):\n",
    "        cur_board = self.game.board\n",
    "        \n",
    "        buf = []\n",
    "        for d in range(4):\n",
    "            self.testgame.board = cur_board\n",
    "            self.testgame.move(d)\n",
    "            buf.append(self.testgame.board.astype(int))\n",
    "            #print(buf[d])\n",
    "        tmp = np.vstack((np.hstack((buf[0],buf[3])) ,np.hstack((buf[1],buf[2])))).flatten().tolist()\n",
    "        new = [int(math.log(i,2)) if i>0 else i for i in tmp]\n",
    "        img = np.array(new).astype(\"float32\")/16\n",
    "        imgs = np.array(img)\n",
    "        input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={'images': imgs}, shuffle=False)\n",
    "        preds = list(model.predict(input_fn))\n",
    "\n",
    "        direction = preds[0]\n",
    "        return direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 1\n",
      "======Direction: up======\n",
      "State:\t       0       2       0       2\n",
      "\t       0       4       0       0\n",
      "\t       0       0       0       0\n",
      "\t       0       0       0       0\n",
      "Score: 4\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 2\n",
      "======Direction: up======\n",
      "State:\t       0       2       0       2\n",
      "\t       0       4       0       0\n",
      "\t       4       0       0       0\n",
      "\t       0       0       0       0\n",
      "Score: 4\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 3\n",
      "======Direction: left======\n",
      "State:\t       4       0       0       0\n",
      "\t       4       0       0       2\n",
      "\t       4       0       0       0\n",
      "\t       0       0       0       0\n",
      "Score: 4\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 4\n",
      "======Direction: left======\n",
      "State:\t       4       0       0       0\n",
      "\t       4       2       0       4\n",
      "\t       4       0       0       0\n",
      "\t       0       0       0       0\n",
      "Score: 4\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 5\n",
      "======Direction: left======\n",
      "State:\t       4       0       0       0\n",
      "\t       4       2       4       0\n",
      "\t       4       0       0       0\n",
      "\t       0       4       0       0\n",
      "Score: 4\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 6\n",
      "======Direction: left======\n",
      "State:\t       4       0       0       0\n",
      "\t       4       2       4       4\n",
      "\t       4       0       0       0\n",
      "\t       4       0       0       0\n",
      "Score: 4\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 7\n",
      "======Direction: right======\n",
      "State:\t       0       0       0       4\n",
      "\t       2       4       2       8\n",
      "\t       0       0       0       4\n",
      "\t       0       0       0       4\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 8\n",
      "======Direction: left======\n",
      "State:\t       4       0       0       4\n",
      "\t       2       4       2       8\n",
      "\t       4       0       0       0\n",
      "\t       4       0       0       0\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 9\n",
      "======Direction: right======\n",
      "State:\t       0       0       0       8\n",
      "\t       2       4       2       8\n",
      "\t       0       0       0       4\n",
      "\t       0       0       2       4\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 10\n",
      "======Direction: right======\n",
      "State:\t       0       0       0       8\n",
      "\t       2       4       2       8\n",
      "\t       2       0       0       4\n",
      "\t       0       0       2       4\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 11\n",
      "======Direction: right======\n",
      "State:\t       0       0       0       8\n",
      "\t       2       4       2       8\n",
      "\t       0       0       2       4\n",
      "\t       0       2       2       4\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 12\n",
      "======Direction: right======\n",
      "State:\t       2       0       0       8\n",
      "\t       2       4       2       8\n",
      "\t       0       0       2       4\n",
      "\t       0       0       4       4\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 13\n",
      "======Direction: right======\n",
      "State:\t       0       0       2       8\n",
      "\t       2       4       2       8\n",
      "\t       4       0       2       4\n",
      "\t       0       0       0       8\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 14\n",
      "======Direction: left======\n",
      "State:\t       2       8       0       2\n",
      "\t       2       4       2       8\n",
      "\t       4       2       4       0\n",
      "\t       8       0       0       0\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 15\n",
      "======Direction: down======\n",
      "State:\t       0       0       0       0\n",
      "\t       4       8       0       2\n",
      "\t       4       4       2       2\n",
      "\t       8       2       4       8\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 16\n",
      "======Direction: down======\n",
      "State:\t       0       0       0       2\n",
      "\t       0       8       0       0\n",
      "\t       8       4       2       4\n",
      "\t       8       2       4       8\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 17\n",
      "======Direction: left======\n",
      "State:\t       2       0       0       0\n",
      "\t       8       0       2       0\n",
      "\t       8       4       2       4\n",
      "\t       8       2       4       8\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 18\n",
      "======Direction: left======\n",
      "State:\t       2       4       0       0\n",
      "\t       8       2       0       0\n",
      "\t       8       4       2       4\n",
      "\t       8       2       4       8\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 19\n",
      "======Direction: left======\n",
      "State:\t       2       4       2       0\n",
      "\t       8       2       0       0\n",
      "\t       8       4       2       4\n",
      "\t       8       2       4       8\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 20\n",
      "======Direction: left======\n",
      "State:\t       2       4       2       2\n",
      "\t       8       2       0       0\n",
      "\t       8       4       2       4\n",
      "\t       8       2       4       8\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 21\n",
      "======Direction: left======\n",
      "State:\t       2       4       4       0\n",
      "\t       8       2       0       4\n",
      "\t       8       4       2       4\n",
      "\t       8       2       4       8\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 22\n",
      "======Direction: left======\n",
      "State:\t       2       8       0       2\n",
      "\t       8       2       4       0\n",
      "\t       8       4       2       4\n",
      "\t       8       2       4       8\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 23\n",
      "======Direction: right======\n",
      "State:\t       0       2       8       2\n",
      "\t       2       8       2       4\n",
      "\t       8       4       2       4\n",
      "\t       8       2       4       8\n",
      "Score: 8\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 24\n",
      "======Direction: down======\n",
      "State:\t       0       2       0       4\n",
      "\t       0       8       8       2\n",
      "\t       2       4       4       8\n",
      "\t      16       2       4       8\n",
      "Score: 16\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 25\n",
      "======Direction: down======\n",
      "State:\t       0       2       2       0\n",
      "\t       0       8       0       4\n",
      "\t       2       4       8       2\n",
      "\t      16       2       8      16\n",
      "Score: 16\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 26\n",
      "======Direction: right======\n",
      "State:\t       0       0       0       4\n",
      "\t       0       2       8       4\n",
      "\t       2       4       8       2\n",
      "\t      16       2       8      16\n",
      "Score: 16\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 27\n",
      "======Direction: right======\n",
      "State:\t       0       2       0       4\n",
      "\t       0       2       8       4\n",
      "\t       2       4       8       2\n",
      "\t      16       2       8      16\n",
      "Score: 16\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 28\n",
      "======Direction: down======\n",
      "State:\t       0       0       4       0\n",
      "\t       0       4       0       8\n",
      "\t       2       4       8       2\n",
      "\t      16       2      16      16\n",
      "Score: 16\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 29\n",
      "======Direction: down======\n",
      "State:\t       0       0       4       0\n",
      "\t       0       0       4       8\n",
      "\t       2       8       8       2\n",
      "\t      16       2      16      16\n",
      "Score: 16\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 30\n",
      "======Direction: right======\n",
      "State:\t       0       0       0       4\n",
      "\t       0       0       4       8\n",
      "\t       2       2      16       2\n",
      "\t       0      16       2      32\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 31\n",
      "======Direction: left======\n",
      "State:\t       4       0       2       0\n",
      "\t       4       8       0       0\n",
      "\t       4      16       2       0\n",
      "\t      16       2      32       0\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 32\n",
      "======Direction: right======\n",
      "State:\t       4       0       4       2\n",
      "\t       0       0       4       8\n",
      "\t       0       4      16       2\n",
      "\t       0      16       2      32\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 33\n",
      "======Direction: left======\n",
      "State:\t       8       2       0       4\n",
      "\t       4       8       0       0\n",
      "\t       4      16       2       0\n",
      "\t      16       2      32       0\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 34\n",
      "======Direction: left======\n",
      "State:\t       8       2       4       0\n",
      "\t       4       8       4       0\n",
      "\t       4      16       2       0\n",
      "\t      16       2      32       0\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 35\n",
      "======Direction: left======\n",
      "State:\t       8       2       4       4\n",
      "\t       4       8       4       0\n",
      "\t       4      16       2       0\n",
      "\t      16       2      32       0\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 36\n",
      "======Direction: down======\n",
      "State:\t       0       2       0       2\n",
      "\t       8       8       8       0\n",
      "\t       8      16       2       0\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 37\n",
      "======Direction: right======\n",
      "State:\t       4       0       0       4\n",
      "\t       0       0       8      16\n",
      "\t       0       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 38\n",
      "======Direction: right======\n",
      "State:\t       4       0       0       8\n",
      "\t       0       0       8      16\n",
      "\t       0       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 39\n",
      "======Direction: right======\n",
      "State:\t       0       0       4       8\n",
      "\t       0       2       8      16\n",
      "\t       0       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 40\n",
      "======Direction: down======\n",
      "State:\t       4       0       4       8\n",
      "\t       0       2       8      16\n",
      "\t       0       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 41\n",
      "======Direction: down======\n",
      "State:\t       4       0       4       8\n",
      "\t       0       2       8      16\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 42\n",
      "======Direction: right======\n",
      "State:\t       2       0       8       8\n",
      "\t       0       2       8      16\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 43\n",
      "======Direction: right======\n",
      "State:\t       0       2       2      16\n",
      "\t       0       2       8      16\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 44\n",
      "======Direction: right======\n",
      "State:\t       2       0       4      16\n",
      "\t       0       2       8      16\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 45\n",
      "======Direction: down======\n",
      "State:\t       0       2       4       0\n",
      "\t       2       2       8      32\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 46\n",
      "======Direction: down======\n",
      "State:\t       0       0       4       4\n",
      "\t       2       4       8      32\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 47\n",
      "======Direction: down======\n",
      "State:\t       0       2       4       4\n",
      "\t       2       4       8      32\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 48\n",
      "======Direction: right======\n",
      "State:\t       0       2       2       8\n",
      "\t       2       4       8      32\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 49\n",
      "======Direction: right======\n",
      "State:\t       2       0       4       8\n",
      "\t       2       4       8      32\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 50\n",
      "======Direction: right======\n",
      "State:\t       4       2       4       8\n",
      "\t       2       4       8      32\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "Iter: 51\n",
      "======Direction: down======\n",
      "State:\t       4       2       4       8\n",
      "\t       2       4       8      32\n",
      "\t       4       8      16       2\n",
      "\t      16       2      32       4\n",
      "Score: 32\n",
      "You lose! Score: 32\n"
     ]
    }
   ],
   "source": [
    "game = Game(4, random=False)\n",
    "agent = MyAgent(game, display=display1)\n",
    "agent.play(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4., 2., 2.],\n",
       "       [2., 2., 4., 4.],\n",
       "       [0., 0., 2., 2.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n",
      "INFO:tensorflow:Restoring parameters from ./mymodels/model4/model.ckpt-130000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-241-902154518744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcur_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mstep1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtestgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_board\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstep2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-232-f8b15c31fe12>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m         input_fn = tf.estimator.inputs.numpy_input_fn(\n\u001b[1;32m     23\u001b[0m             x={'images': imgs}, shuffle=False)\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path)\u001b[0m\n\u001b[1;32m    338\u001b[0m           input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[1;32m    339\u001b[0m       estimator_spec = self._call_model_fn(features, None,\n\u001b[0;32m--> 340\u001b[0;31m                                            model_fn_lib.ModeKeys.PREDICT)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       with training.MonitoredSession(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode)\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-209-cddf205a4d8d>\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# need to create 2 distinct computation graphs that still share the same weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlogits_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlogits_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-208-30423d40656a>\u001b[0m in \u001b[0;36mconv_net\u001b[0;34m(x_dict, n_classes, dropout, reuse, is_training)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Apply Dropout (if is_training is False, dropout is not applied)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Output layer, class prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/layers/core.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(inputs, rate, noise_shape, seed, training, name)\u001b[0m\n\u001b[1;32m    300\u001b[0m   \"\"\"\n\u001b[1;32m    301\u001b[0m   \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \"\"\"\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     with vs.variable_scope(self._scope,\n\u001b[0;32m--> 433\u001b[0;31m                            reuse=self.built or self._reuse) as scope:\n\u001b[0m\u001b[1;32m    434\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mvariable_scope\u001b[0;34m(name_or_scope, default_name, values, initializer, regularizer, caching_device, partitioner, custom_getter, reuse, dtype, use_resource)\u001b[0m\n\u001b[1;32m   1545\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname_or_scope\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVariableScope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1548\u001b[0m         raise TypeError(\"VariableScope: name_or_scope must be a string or \"\n\u001b[1;32m   1549\u001b[0m                         \"VariableScope.\")\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "testgame = Game(4, random=False)\n",
    "testgame.enable_rewrite_board = True\n",
    "cur_board = testgame.board\n",
    "agent1 = MyAgent(testgame, display=None)\n",
    "agent2 = ExpectiMaxAgent(testgame, display=None)\n",
    "\n",
    "err = 0\n",
    "for i in range(100):\n",
    "    cur_board = testgame.board\n",
    "    step1 = agent1.step()\n",
    "    testgame.board = cur_board\n",
    "    step2 = agent2.step()\n",
    "    testgame.move(step2)\n",
    "    if(step1!=step2):\n",
    "        err += 1\n",
    "    \n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
